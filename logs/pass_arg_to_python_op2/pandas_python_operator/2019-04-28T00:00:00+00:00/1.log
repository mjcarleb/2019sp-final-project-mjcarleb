[2019-04-29 13:02:09,239] {__init__.py:1139} INFO - Dependencies all met for <TaskInstance: pass_arg_to_python_op2.pandas_python_operator 2019-04-28T00:00:00+00:00 [queued]>
[2019-04-29 13:02:09,243] {__init__.py:1139} INFO - Dependencies all met for <TaskInstance: pass_arg_to_python_op2.pandas_python_operator 2019-04-28T00:00:00+00:00 [queued]>
[2019-04-29 13:02:09,243] {__init__.py:1353} INFO - 
--------------------------------------------------------------------------------
[2019-04-29 13:02:09,243] {__init__.py:1354} INFO - Starting attempt 1 of 1
[2019-04-29 13:02:09,243] {__init__.py:1355} INFO - 
--------------------------------------------------------------------------------
[2019-04-29 13:02:09,252] {__init__.py:1374} INFO - Executing <Task(PythonOperator): pandas_python_operator> on 2019-04-28T00:00:00+00:00
[2019-04-29 13:02:09,253] {base_task_runner.py:119} INFO - Running: ['airflow', 'run', 'pass_arg_to_python_op2', 'pandas_python_operator', '2019-04-28T00:00:00+00:00', '--job_id', '159', '--raw', '-sd', 'DAGS_FOLDER/arg_passing.py', '--cfg_path', '/tmp/tmp9m0iakzf']
[2019-04-29 13:02:09,541] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator /home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/configuration.py:214: FutureWarning: The task_runner setting in [core] has the old default value of 'BashTaskRunner'. This value has been changed to 'StandardTaskRunner' in the running config, but please update your config before Apache Airflow 2.0.
[2019-04-29 13:02:09,542] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   FutureWarning,
[2019-04-29 13:02:09,712] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator [2019-04-29 13:02:09,712] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-04-29 13:02:09,876] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator [2019-04-29 13:02:09,876] {__init__.py:305} INFO - Filling up the DagBag from /home/mjcarleb/HESWork/CSCI-E29/2019sp-airflow_project-mjcarleb/dags/arg_passing.py
[2019-04-29 13:02:10,028] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator [2019-04-29 13:02:10,028] {cli.py:517} INFO - Running <TaskInstance: pass_arg_to_python_op2.pandas_python_operator 2019-04-28T00:00:00+00:00 [running]> on host localhost.localdomain
[2019-04-29 13:02:10,034] {python_operator.py:104} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=pass_arg_to_python_op2
AIRFLOW_CTX_TASK_ID=pandas_python_operator
AIRFLOW_CTX_EXECUTION_DATE=2019-04-28T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-28T00:00:00+00:00
[2019-04-29 13:02:10,034] {__init__.py:1580} ERROR - read_from_csv() got an unexpected keyword argument 'dag'
Traceback (most recent call last):
  File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/models/__init__.py", line 1441, in _run_raw_task
    result = task_copy.execute(context=context)
  File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 112, in execute
    return_value = self.execute_callable()
  File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 117, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
TypeError: read_from_csv() got an unexpected keyword argument 'dag'
[2019-04-29 13:02:10,035] {__init__.py:1611} INFO - Marking task as FAILED.
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator Traceback (most recent call last):
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   File "/home/mjcarleb/anaconda3/envs/airflow4/bin/airflow", line 32, in <module>
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator     args.func(args)
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/utils/cli.py", line 74, in wrapper
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator     return f(*args, **kwargs)
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/bin/cli.py", line 523, in run
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator     _run(args, dag, ti)
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/bin/cli.py", line 442, in _run
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator     pool=args.pool,
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/utils/db.py", line 73, in wrapper
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator     return func(*args, **kwargs)
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/models/__init__.py", line 1441, in _run_raw_task
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator     result = task_copy.execute(context=context)
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 112, in execute
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator     return_value = self.execute_callable()
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator   File "/home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 117, in execute_callable
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator     return self.python_callable(*self.op_args, **self.op_kwargs)
[2019-04-29 13:02:10,049] {base_task_runner.py:101} INFO - Job 159: Subtask pandas_python_operator TypeError: read_from_csv() got an unexpected keyword argument 'dag'
[2019-04-29 13:02:14,234] {logging_mixin.py:95} INFO - [2019-04-29 13:02:14,234] {jobs.py:2562} INFO - Task exited with return code 1
