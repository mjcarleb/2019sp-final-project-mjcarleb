[2019-04-29 11:39:51,900] {__init__.py:1139} INFO - Dependencies all met for <TaskInstance: read_csv_into_dataframe.touch_as_proof 2019-04-28T00:00:00+00:00 [queued]>
[2019-04-29 11:39:51,908] {__init__.py:1139} INFO - Dependencies all met for <TaskInstance: read_csv_into_dataframe.touch_as_proof 2019-04-28T00:00:00+00:00 [queued]>
[2019-04-29 11:39:51,908] {__init__.py:1353} INFO - 
--------------------------------------------------------------------------------
[2019-04-29 11:39:51,908] {__init__.py:1354} INFO - Starting attempt 1 of 1
[2019-04-29 11:39:51,908] {__init__.py:1355} INFO - 
--------------------------------------------------------------------------------
[2019-04-29 11:39:51,920] {__init__.py:1374} INFO - Executing <Task(BashOperator): touch_as_proof> on 2019-04-28T00:00:00+00:00
[2019-04-29 11:39:51,920] {base_task_runner.py:119} INFO - Running: ['airflow', 'run', 'read_csv_into_dataframe', 'touch_as_proof', '2019-04-28T00:00:00+00:00', '--job_id', '147', '--raw', '-sd', 'DAGS_FOLDER/python_operator_challenge.py', '--cfg_path', '/tmp/tmp3_au30y5']
[2019-04-29 11:39:52,196] {base_task_runner.py:101} INFO - Job 147: Subtask touch_as_proof /home/mjcarleb/anaconda3/envs/airflow4/lib/python3.7/site-packages/airflow/configuration.py:214: FutureWarning: The task_runner setting in [core] has the old default value of 'BashTaskRunner'. This value has been changed to 'StandardTaskRunner' in the running config, but please update your config before Apache Airflow 2.0.
[2019-04-29 11:39:52,196] {base_task_runner.py:101} INFO - Job 147: Subtask touch_as_proof   FutureWarning,
[2019-04-29 11:39:52,340] {base_task_runner.py:101} INFO - Job 147: Subtask touch_as_proof [2019-04-29 11:39:52,340] {__init__.py:51} INFO - Using executor SequentialExecutor
[2019-04-29 11:39:52,474] {base_task_runner.py:101} INFO - Job 147: Subtask touch_as_proof [2019-04-29 11:39:52,474] {__init__.py:305} INFO - Filling up the DagBag from /home/mjcarleb/HESWork/CSCI-E29/2019sp-airflow_project-mjcarleb/dags/python_operator_challenge.py
[2019-04-29 11:39:52,615] {base_task_runner.py:101} INFO - Job 147: Subtask touch_as_proof [2019-04-29 11:39:52,615] {cli.py:517} INFO - Running <TaskInstance: read_csv_into_dataframe.touch_as_proof 2019-04-28T00:00:00+00:00 [running]> on host localhost.localdomain
[2019-04-29 11:39:52,623] {bash_operator.py:81} INFO - Tmp dir root location: 
 /tmp
[2019-04-29 11:39:52,623] {bash_operator.py:90} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_ID=read_csv_into_dataframe
AIRFLOW_CTX_TASK_ID=touch_as_proof
AIRFLOW_CTX_EXECUTION_DATE=2019-04-28T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-04-28T00:00:00+00:00
[2019-04-29 11:39:52,623] {bash_operator.py:104} INFO - Temporary script location: /tmp/airflowtmpwyldjgen/touch_as_proofmjos0z2j
[2019-04-29 11:39:52,623] {bash_operator.py:114} INFO - Running command: touch ~/iwashere.txt
[2019-04-29 11:39:52,627] {bash_operator.py:123} INFO - Output:
[2019-04-29 11:39:52,628] {bash_operator.py:131} INFO - Command exited with return code 0
[2019-04-29 11:39:56,892] {logging_mixin.py:95} INFO - [2019-04-29 11:39:56,892] {jobs.py:2562} INFO - Task exited with return code 0
